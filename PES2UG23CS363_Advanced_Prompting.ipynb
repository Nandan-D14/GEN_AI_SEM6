{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Nandan D | PES2UG23CS363 | F**\n",
        "## LangChain Assignment\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "14V1X4oL7jkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 3a: Chain of Thought (CoT)"
      ],
      "metadata": {
        "id": "j3Cwn8cN7qmy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eog8ZjDn7ehv",
        "outputId": "6c317118-9f0e-4c34-8cb9-28a200f275e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P364Kwtd7-SL",
        "outputId": "1ad9bd47-9b11-46d0-f6e5-202caa70e655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concept: Latent Reasoning"
      ],
      "metadata": {
        "id": "-HuyTUDr9cH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
        "\n",
        "# 1. Standard Prompt (Direct Answer)\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5WBMp5a8le5",
        "outputId": "c85720e0-b974-4acf-8293-6051282a4376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
            "\n",
            "2 cans * 3 tennis balls per can = 6 tennis balls\n",
            "\n",
            "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
            "\n",
            "5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Experiment: A Tricky Math Problem"
      ],
      "metadata": {
        "id": "zEryCle69gxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. CoT Prompt (Magic Phrase)\n",
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oiISLJl8oSD",
        "outputId": "b96bca09-ae7d-4da8-c82e-049662e89cb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
            "\n",
            "1. Roger already has 5 tennis balls.\n",
            "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
            "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3b: Tree of Thoughts (ToT) & Graph of Thoughts (GoT)"
      ],
      "metadata": {
        "id": "IAp0PX8C8wVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
      ],
      "metadata": {
        "id": "XmQC8ZFM8xsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COT"
      ],
      "metadata": {
        "id": "XinAdQht9L8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
        "\n",
        "# Step 1: The Branch Generator\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# Step 2: The Judge\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three proposed solutions for: '{problem}'\n",
        "\n",
        "    1: {sol1}\n",
        "    2: {sol2}\n",
        "    3: {sol3}\n",
        "\n",
        "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Chain: Input -> Branches -> Judge -> Output\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORKW4Itq83TT",
        "outputId": "1810bc01-242c-4aa0-c1c7-3190d96d5c97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tree of Thoughts (ToT) Result ---\n",
            "As a child psychologist, I would recommend Solution 3: Create a \"Veggie Face\" on Their Plate as the most sustainable approach to encouraging a 5-year-old to eat vegetables. Here's why:\n",
            "\n",
            "1. **Involves the child in the process**: This approach encourages the child to participate in creating a fun and engaging meal, which fosters a sense of ownership and control over the experience. By letting the child decide how the face looks, they feel more invested in the meal and are more likely to try the vegetables.\n",
            "2. **Develops problem-solving skills**: Creating a veggie face requires the child to think creatively and come up with solutions to fit the vegetables together. This helps develop their problem-solving skills and encourages critical thinking.\n",
            "3. **Builds self-esteem**: By letting the child take the lead in creating the veggie face, they feel proud of their creation and more confident in their ability to try new foods.\n",
            "4. **Promotes a positive relationship with vegetables**: By making mealtime enjoyable and interactive, the child develops a more positive association with vegetables, which can lead to a lifelong habit of eating a balanced diet.\n",
            "5. **Does not involve bribery**: Unlike Solution 2, which involves hiding vegetables in other foods, this approach does not rely on deception or bribery. Instead, it focuses on making mealtime a fun and engaging experience.\n",
            "\n",
            "In contrast, Solution 1: Create a Vegetable Face on Their Plate, while creative and engaging, may not be as sustainable in the long term, as it relies on the child's initial excitement and novelty of the experience. Solution 2: \"Dirt Cups\" with Hidden Veggies, on the other hand, may be seen as deceptive and could undermine trust between the child and the parent, making it less effective in promoting a positive relationship with vegetables.\n",
            "\n",
            "Overall, Solution 3: Create a \"Veggie Face\" on Their Plate is a sustainable and effective approach to encouraging a 5-year-old to eat vegetables, as it involves the child in the process, develops problem-solving skills, builds self-esteem, promotes a positive relationship with vegetables, and does not involve bribery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GOT\n"
      ],
      "metadata": {
        "id": "6stjU6TZ9KJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The Generator (Divergence)\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# 2. The Aggregator (Convergence)\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three movie ideas for the topic '{topic}':\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romance: {draft_romance}\n",
        "    3. Horror: {draft_horror}\n",
        "\n",
        "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
        "    Write one paragraph.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 3. The Chain\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(\"Time Travel\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGShchiI9H2B",
        "outputId": "98e04dba-ba99-4567-f331-225214e16b3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Graph of Thoughts (GoT) Result ---\n",
            "Here's a new movie idea that combines the technology of Sci-Fi, the passion of Romance, and the fear of Horror:\n",
            "\n",
            "\"Moonfall\" follows Dr. Emma Taylor, a brilliant and reclusive physicist who has spent her entire career studying the mysteries of time. When she finally cracks the code to time travel, she's ecstatic, but her excitement is short-lived as she discovers a way to manipulate the fabric of time itself. As she experiments with her invention, she meets Ryan, a charming and handsome pilot who has been sent back in time from a dystopian future where the world is on the brink of collapse. As they navigate through the complexities of time travel, they realize that their love is the key to preventing the apocalypse, but a malevolent entity, born from the darkness of the future, begins to hunt them down, threatening to destroy not just their love, but the very fabric of reality itself. As they fight to survive and prevent the impending doom, they must also confront the ultimate question: can their love be strong enough to overcome the forces of time itself, or will they succumb to the darkness that threatens to consume them?\n"
          ]
        }
      ]
    }
  ]
}