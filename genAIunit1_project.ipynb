{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn2LWFpNTRicX+YutSQtwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandan-D14/GEN_AI_SEM6/blob/main/genAIunit1_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Name : Nandan D\n",
        "## SRN : PES2UG23CS363\n",
        "## Section : F\n"
      ],
      "metadata": {
        "id": "Jfmque0KdDlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers gradio torch"
      ],
      "metadata": {
        "id": "VADEFaLq-Ln3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwzSNMSA7GRu",
        "outputId": "3cf3ea5f-5d23-40c0-abfe-ebbeb848d385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a text-generation pipeline from the transformers library. It uses the pre-trained gpt2 model to perform text generation tasks."
      ],
      "metadata": {
        "id": "x0eLRCMIcpGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storyteller = pipeline('text-generation', model='gpt2')"
      ],
      "metadata": {
        "id": "gwHA33TB-XVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt for GPT 2 to predict next token"
      ],
      "metadata": {
        "id": "vtEgsfarcGgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"Once upon a time their was beautiful kingdom  \"\n",
        ")\n"
      ],
      "metadata": {
        "id": "NVqMXU8f-XIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seed (Randomness)"
      ],
      "metadata": {
        "id": "EivueF9acRMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "id": "ZBx8FeSvV2g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Configurations\n",
        "\n",
        "the storyteller to create a story based on your prompt with specific settings. It then extracts the generated text from the story output. Finally, it prints each sentence of that generated text.\n",
        "\n",
        "temp = 0.5 for creativity if it set to above 0.5 it start more hallucinate"
      ],
      "metadata": {
        "id": "ttEQBpSkcXHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = storyteller(\n",
        "    prompt,\n",
        "    max_new_tokens=200,\n",
        "    truncation=False,\n",
        "    do_sample=True,\n",
        "    temperature=0.5,\n",
        "    top_p=0.2,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=50256\n",
        ")\n",
        "\n",
        "text = story[0][\"generated_text\"]\n",
        "sentences = text.replace(\"?\", \".\").replace(\"!\", \".\").split(\".\")\n",
        "print(\"Generated Story:\\n\")\n",
        "for s in sentences:\n",
        "    s = s.strip()\n",
        "    if s:\n",
        "        print(s + \".\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emxBLqgc-W6p",
        "outputId": "7aa13676-f7a3-4cfc-c2b0-4fdfb92ca94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story:\n",
            "\n",
            "Once upon a time their was beautiful kingdom   and the people of the land were so happy that they would not leave their homes.\n",
            "The people were not happy with the king's actions.\n",
            "They were angry with him for his actions and for the fact that he had not been able to protect them.\n",
            "The people felt that the King was not able or willing to defend them and they were furious with them for not being able and willing.\n",
            "They were also angry that their king had been so weak and so incompetent.\n",
            "Their anger was so strong that it was hard to believe that his strength was even possible.\n",
            "It was a feeling that was very strong and very powerful.\n",
            "In the end, the kingdom was destroyed and the world was left with a terrible mess.\n",
            "\"I am sorry for your loss.\n",
            "I will not be able do anything to you.\n",
            "You are my friend.\n",
            "Please forgive me for my actions.\n",
            "\"\n",
            "A voice came from the back of his head.\n",
            "He was looking at the man who was sitting on the throne.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations\n",
        "\n",
        "* Model Limitation: GPT-2 functions primarily as a 'next-word predictor' (next-token prediction) and lacks intrinsic understanding of complex narrative elements such as story structure, character arcs, and long-term plot coherence.\n",
        "* Inconsistency and Hallucination: Despite the use of non-deterministic sampling, prompt shaping, and parameter tuning (temperature, top-p, etc.), the model frequently struggled, leading to incoherent plots, character inconsistencies, repetitive text, and the introduction of random 'hallucinated' details."
      ],
      "metadata": {
        "id": "UGuYKWinbsYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "This project demonstrates the practical limitations of using GPT-2 for creative storytelling tasks without fine-tuning. While basic story-like text can be generated, achieving meaningful, coherent, and creative narratives is challenging due to the model’s age and architectural constraints. The assignment successfully highlights the importance of model selection, prompt design, and generation parameter tuning, as well as the necessity of newer or fine-tuned models for advanced generative applications.\n"
      ],
      "metadata": {
        "id": "bAs4G-9kbO86"
      }
    }
  ]
}